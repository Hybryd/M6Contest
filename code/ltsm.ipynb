{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf23004",
   "metadata": {},
   "source": [
    "# Model : LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4618f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 10:13:16.846733: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-22 10:13:16.846765: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6a63d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date Symbol       Open       High        Low      Close  \\\n",
      "0       2013-01-02   ABBV  23.848844  24.176665  23.288819  23.985435   \n",
      "1       2013-01-03   ABBV  23.903484  23.903484  23.329800  23.787382   \n",
      "2       2013-01-04   ABBV  23.643949  23.828348  23.391256  23.486870   \n",
      "3       2013-01-07   ABBV  23.322972  24.210815  23.322972  23.534687   \n",
      "4       2013-01-08   ABBV  23.418585  23.657618  22.783435  23.022469   \n",
      "...            ...    ...        ...        ...        ...        ...   \n",
      "542265  2022-02-11    VXX  20.469999  23.870001  20.295000  23.240000   \n",
      "542266  2022-02-14    VXX  23.309999  24.799999  23.010000  23.309999   \n",
      "542267  2022-02-15    VXX  21.680000  22.219999  21.330000  21.389999   \n",
      "542268  2022-02-16    VXX  21.700001  22.139999  20.459999  20.530001   \n",
      "542269  2022-02-17    VXX  21.709999  23.090000  21.620001  22.959999   \n",
      "\n",
      "           Volume  \n",
      "0        13767900  \n",
      "1        16739300  \n",
      "2        21372100  \n",
      "3        17897100  \n",
      "4        17863300  \n",
      "...           ...  \n",
      "542265  116830300  \n",
      "542266  102120800  \n",
      "542267   55678200  \n",
      "542268   57347600  \n",
      "542269   66985600  \n",
      "\n",
      "[542270 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/ohlcv_m6.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb7b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df):\n",
    "    # PARAMETERS\n",
    "    split_percent = 0.99 # Split ratio for the train/test split\n",
    "    look_back = 20 # Look back for the LTSM\n",
    "    num_epochs = 100 # Number of epochs for the LTSM\n",
    "    num_prediction = 30 # Make forecast for the next month\n",
    "    \n",
    "    # Forecast dates\n",
    "    last_date = df['Date'].values[-1]\n",
    "    forecast_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()\n",
    "    \n",
    "    # This dataframe stores the forecasts of the next month for every symbols\n",
    "    res = pd.DataFrame()\n",
    "    res[\"Date\"] = forecast_dates\n",
    "    \n",
    "    # Get list of symbols\n",
    "    symbols = pd.unique(df[\"Symbol\"].values.ravel())\n",
    "\n",
    "    for symbol in symbols:\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(symbol)\n",
    "        \n",
    "        # Get data. Keep only Close values\n",
    "        dataframe = df[df[\"Symbol\"]==symbol]\n",
    "        #print(\"##############\",len(dataframe))\n",
    "        dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%Y-%m-%d\")\n",
    "        dataframe.set_axis(dataframe['Date'], inplace=True)\n",
    "        dataframe.drop(columns=['Open', 'High', 'Low', 'Volume'], inplace=True)\n",
    "        close_data = dataframe[\"Close\"].values.reshape(-1,1)\n",
    "        \n",
    "        #print(\"##############\",len(close_data))\n",
    "        \n",
    "        # Split\n",
    "        split = int(split_percent*len(close_data))\n",
    "        close_train = close_data[:split]\n",
    "        close_test = close_data[split:]\n",
    "        date_train = dataframe['Date'][:split]\n",
    "        date_test = dataframe['Date'][split:]\n",
    "        \n",
    "        train_generator = TimeseriesGenerator(close_train, close_train, length=look_back, batch_size=20)\n",
    "        test_generator = TimeseriesGenerator(close_test, close_test, length=look_back, batch_size=1)\n",
    "\n",
    "        # Create the model (LTSM)\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            LSTM(10,\n",
    "                activation='relu',\n",
    "                input_shape=(look_back,1))\n",
    "        )\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        dot_img_file = symbol+\"_model.png\"\n",
    "        tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(train_generator, epochs=num_epochs, verbose=2)\n",
    "        \n",
    "        # Predictions\n",
    "        prediction = model.predict(test_generator)\n",
    "\n",
    "        close_train = close_train.reshape((-1))\n",
    "        close_test = close_test.reshape((-1))\n",
    "        prediction = prediction.reshape((-1))\n",
    "                \n",
    "        # Make prediction for the next month\n",
    "        close_data = close_data.reshape((-1))\n",
    "\n",
    "       \n",
    "        prediction_list = close_data[-look_back:]\n",
    "\n",
    "        for _ in range(num_prediction):\n",
    "            x = prediction_list[-look_back:]\n",
    "            x = x.reshape((1, look_back, 1))\n",
    "            out = model.predict(x)[0][0]\n",
    "            prediction_list = np.append(prediction_list, out)\n",
    "        forecast = prediction_list[look_back-1:]\n",
    "\n",
    "        \n",
    "        # Transform results as dataframes\n",
    "        df_train = pd.DataFrame({\"Date\":date_train,\"Train\" : close_train})\n",
    "        df_test = pd.DataFrame({\"Date\":date_test,\"Test\" : close_test})\n",
    "        df_prediction = pd.DataFrame({\"Date\":date_test[look_back:],\"Prediction\" : prediction})\n",
    "        df_forecast = pd.DataFrame({\"Date\":forecast_dates,\"Forecast\" : forecast})\n",
    "        res[symbol] = forecast\n",
    "        \n",
    "        \n",
    "    return res#df_train, df_test, df_prediction, df_forecast\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85152acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 10:13:21.517414: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-22 10:13:21.519069: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-22 10:13:21.519095: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-22 10:13:21.519128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kfdell): /proc/driver/nvidia/version does not exist\n",
      "2022-02-22 10:13:21.519505: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 10:13:21.519878: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-22 10:13:21.879116: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-22 10:13:21.902557: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2594140000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 - 2s - loss: 57020.9102\n",
      "Epoch 2/100\n",
      "113/113 - 1s - loss: 22365.8125\n",
      "Epoch 3/100\n",
      "113/113 - 1s - loss: 4077.9761\n",
      "Epoch 4/100\n",
      "113/113 - 1s - loss: 1648.9138\n",
      "Epoch 5/100\n",
      "113/113 - 1s - loss: 8423.1504\n",
      "Epoch 6/100\n",
      "113/113 - 1s - loss: 7396.3374\n",
      "Epoch 7/100\n",
      "113/113 - 1s - loss: 5195.9585\n",
      "Epoch 8/100\n",
      "113/113 - 1s - loss: 5109.0830\n",
      "Epoch 9/100\n",
      "113/113 - 1s - loss: 5034.0278\n",
      "Epoch 10/100\n",
      "113/113 - 1s - loss: 4955.4619\n",
      "Epoch 11/100\n",
      "113/113 - 1s - loss: 4873.5801\n",
      "Epoch 12/100\n",
      "113/113 - 1s - loss: 4788.6011\n",
      "Epoch 13/100\n",
      "113/113 - 1s - loss: 4701.1138\n",
      "Epoch 14/100\n",
      "113/113 - 0s - loss: 4611.0669\n",
      "Epoch 15/100\n",
      "113/113 - 1s - loss: 4516.8618\n",
      "Epoch 16/100\n",
      "113/113 - 1s - loss: 4402.5293\n",
      "Epoch 17/100\n",
      "113/113 - 1s - loss: 4244.3135\n",
      "Epoch 18/100\n",
      "113/113 - 1s - loss: 4105.2207\n",
      "Epoch 19/100\n",
      "113/113 - 1s - loss: 3997.5562\n",
      "Epoch 20/100\n",
      "113/113 - 1s - loss: 3903.2473\n",
      "Epoch 21/100\n",
      "113/113 - 1s - loss: 3813.7134\n",
      "Epoch 22/100\n",
      "113/113 - 1s - loss: 3726.6509\n",
      "Epoch 23/100\n",
      "113/113 - 1s - loss: 4086.8484\n",
      "Epoch 24/100\n",
      "113/113 - 1s - loss: 3569.6316\n",
      "Epoch 25/100\n",
      "113/113 - 1s - loss: 3500.7695\n",
      "Epoch 26/100\n",
      "113/113 - 1s - loss: 3430.5750\n",
      "Epoch 27/100\n",
      "113/113 - 1s - loss: 3358.9558\n",
      "Epoch 28/100\n",
      "113/113 - 1s - loss: 3285.6570\n",
      "Epoch 29/100\n",
      "113/113 - 1s - loss: 3211.1289\n",
      "Epoch 30/100\n",
      "113/113 - 1s - loss: 3135.5374\n",
      "Epoch 31/100\n",
      "113/113 - 1s - loss: 3058.5801\n",
      "Epoch 32/100\n",
      "113/113 - 1s - loss: 2980.5176\n",
      "Epoch 33/100\n",
      "113/113 - 1s - loss: 2901.5701\n",
      "Epoch 34/100\n",
      "113/113 - 1s - loss: 2821.7825\n",
      "Epoch 35/100\n",
      "113/113 - 1s - loss: 2741.3157\n",
      "Epoch 36/100\n",
      "113/113 - 1s - loss: 2659.6274\n",
      "Epoch 37/100\n",
      "113/113 - 1s - loss: 2578.0806\n",
      "Epoch 38/100\n",
      "113/113 - 1s - loss: 2494.8657\n",
      "Epoch 39/100\n",
      "113/113 - 1s - loss: 2412.2690\n",
      "Epoch 40/100\n",
      "113/113 - 1s - loss: 2328.4685\n",
      "Epoch 41/100\n",
      "113/113 - 1s - loss: 2244.7676\n",
      "Epoch 42/100\n",
      "113/113 - 1s - loss: 2160.7261\n",
      "Epoch 43/100\n",
      "113/113 - 1s - loss: 2076.5918\n",
      "Epoch 44/100\n",
      "113/113 - 1s - loss: 1992.2007\n",
      "Epoch 45/100\n",
      "113/113 - 1s - loss: 1907.7246\n",
      "Epoch 46/100\n",
      "113/113 - 1s - loss: 1823.3450\n",
      "Epoch 47/100\n",
      "113/113 - 1s - loss: 1739.7151\n",
      "Epoch 48/100\n",
      "113/113 - 1s - loss: 1655.3795\n",
      "Epoch 49/100\n",
      "113/113 - 1s - loss: 1572.0867\n",
      "Epoch 50/100\n",
      "113/113 - 1s - loss: 1489.5203\n",
      "Epoch 51/100\n",
      "113/113 - 1s - loss: 1408.1516\n",
      "Epoch 52/100\n",
      "113/113 - 1s - loss: 1326.7881\n",
      "Epoch 53/100\n",
      "113/113 - 1s - loss: 1246.7866\n",
      "Epoch 54/100\n",
      "113/113 - 1s - loss: 1167.5419\n",
      "Epoch 55/100\n",
      "113/113 - 1s - loss: 1089.5698\n",
      "Epoch 56/100\n",
      "113/113 - 1s - loss: 1013.3206\n",
      "Epoch 57/100\n",
      "113/113 - 1s - loss: 937.6343\n",
      "Epoch 58/100\n",
      "113/113 - 1s - loss: 864.7503\n",
      "Epoch 59/100\n",
      "113/113 - 1s - loss: 793.4042\n",
      "Epoch 60/100\n",
      "113/113 - 1s - loss: 724.4051\n",
      "Epoch 61/100\n",
      "113/113 - 1s - loss: 658.1971\n",
      "Epoch 62/100\n",
      "113/113 - 1s - loss: 594.4152\n",
      "Epoch 63/100\n",
      "113/113 - 1s - loss: 534.0635\n",
      "Epoch 64/100\n",
      "113/113 - 1s - loss: 476.5429\n",
      "Epoch 65/100\n",
      "113/113 - 1s - loss: 422.4977\n",
      "Epoch 66/100\n",
      "113/113 - 1s - loss: 372.0888\n",
      "Epoch 67/100\n",
      "113/113 - 1s - loss: 325.2325\n",
      "Epoch 68/100\n",
      "113/113 - 1s - loss: 282.5226\n",
      "Epoch 69/100\n",
      "113/113 - 1s - loss: 243.5128\n",
      "Epoch 70/100\n",
      "113/113 - 1s - loss: 208.9103\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42030/609941966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#df_train, df_test, df_prediction, df_forecast = make_predictions(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mforecasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_42030/2607261064.py\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#df_train, df_test, df_prediction, df_forecast = make_predictions(df)\n",
    "forecasts = make_predictions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a85ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecasts.plot(x=\"Date\", y=list(forecasts.columns[1:]), label=list(forecasts.columns[1:]))\n",
    "#plt.show()\n",
    "forecasts.to_csv(\"forecasts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17334b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
